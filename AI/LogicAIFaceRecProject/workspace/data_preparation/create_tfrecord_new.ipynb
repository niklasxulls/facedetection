{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import *\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "os.chdir('..')\n",
    "join = os.path.join(os.getcwd(), '_global')\n",
    "sys.path.extend([join])\n",
    "from _global.config import *\n",
    "from _global.funcs import *\n",
    "from object_detection.utils import dataset_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    # bytelist isnt able to unpack a string from an eagertensor\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() \n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niklas\\Desktop\\Face_Recognition_Ullsperger\\LogicAIFaceRecProject\\tf\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1800: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def prepare_bbxs(bbxs, width, height):\n",
    "    bbx_to_transform = []\n",
    "    for bbx in bbxs:\n",
    "        temp = bbx\n",
    "        temp[2] += temp[0]\n",
    "        temp[2] /= width\n",
    "        \n",
    "        temp[3] += temp[1]\n",
    "        temp[3] /= height\n",
    "\n",
    "        temp[0] /= width\n",
    "        temp[1] /= height\n",
    "\n",
    "        if temp[0] > 1 or temp[1] > 1 or temp[2] > 1 or temp[2] <= temp[0] or temp[3] > 1 or temp[3] <= temp[1]:\n",
    "            continue\n",
    "\n",
    "        temp.append('x')\n",
    "\n",
    "        bbx_to_transform.append(temp)\n",
    "    return bbx_to_transform\n",
    "\n",
    "\n",
    "def decode_img(img, bbxs):\n",
    "    image = tf.image.decode_jpeg(img , channels=3)\n",
    "\n",
    "    height, width, channels = image.shape\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    image = tf.image.resize(image, [IMAGE_SIZES[0], IMAGE_SIZES[1]])\n",
    "    image = image.numpy()\n",
    "    if(len(bbxs) > 0):\n",
    "        bbx_to_transform = prepare_bbxs(bbxs, width, height)\n",
    "        transformed = transform_resize_w_bbxs(image=image, bboxes=bbx_to_transform)\n",
    "        \n",
    "        bbxs_with_label = transformed['bboxes']\n",
    "        bbxs_return = [bbx[:4] for bbx in bbxs_with_label]\n",
    "\n",
    "        image = tf.convert_to_tensor(transformed['image'])\n",
    "    else:\n",
    "        return image, [[]], [[]]\n",
    "    return image, bbxs_return, bbxs_with_label\n",
    "\n",
    "MASTER_TRANSFORM = A.Compose([\n",
    "           A.OneOf([\n",
    "                A.HorizontalFlip(p=1),\n",
    "                A.RandomRotate90(p=1),\n",
    "                A.VerticalFlip(p=1),\n",
    "            ], p=0.3),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(10, p=1),\n",
    "                A.GaussNoise((1, 60), -50 ,p=1),\n",
    "                A.RandomFog(p=1),\n",
    "                A.ImageCompression(1, 10, p=1.0)  \n",
    "            ], p=0.4),\n",
    "            A.OneOf([\n",
    "                A.RandomBrightness(p=1),\n",
    "                A.RandomGamma(p=1),\n",
    "                A.RandomBrightnessContrast(p=1)\n",
    "            ], p=0.5),\n",
    "            A.RandomScale(scale_limit=0.5, p=0.3),\n",
    "            A.PadIfNeeded(IMAGE_SIZES[0], IMAGE_SIZES[1], border_mode=0, value=[0,0,0]),\n",
    "            A.Crop(0, 0, IMAGE_SIZES[0], IMAGE_SIZES[1], p=1)\n",
    "    ], bbox_params=bbx_params)  \n",
    "\n",
    "\n",
    "def random_augument(img, bbxs):\n",
    "    img_temp = tf.cast(img, dtype=tf.uint8).numpy()\n",
    "    transformed = MASTER_TRANSFORM(image=img_temp, bboxes=bbxs)\n",
    "    return tf.convert_to_tensor(transformed['image']), transformed['bboxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbx_valid(bbx):\n",
    "    return (bbx[0] <= 1 and bbx[0] >=0 and bbx[1] <= 1 and bbx[1] >=0 and bbx[2] <= 1 and bbx[2] >=0\n",
    "           and bbx[3] <= 1 and bbx[3] >=0 and bbx[2] > bbx[0] and bbx[3] > bbx[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_future(filename, bbxs, img_tensor):\n",
    "    x_min = []\n",
    "    x_max = []\n",
    "    y_min = []\n",
    "    y_max = []\n",
    "    labels = []\n",
    "    label_texts = []\n",
    "    img_bytes = tf.io.encode_jpeg(tf.cast(img_tensor, tf.uint8))\n",
    "\n",
    "    for bbx in bbxs:\n",
    "        if not bbx_valid(bbx):\n",
    "            continue\n",
    "        x_min.append(bbx[0])\n",
    "        y_min.append(bbx[1])\n",
    "        x_max.append(bbx[2])\n",
    "        y_max.append(bbx[3])\n",
    "        labels.append(1)\n",
    "        label_texts.append(bytes('face', 'utf-8') )\n",
    "\n",
    "    return tf.train.Example(\n",
    "        features = tf.train.Features(feature = {\n",
    "            'image/filename': tf.train.Feature(bytes_list = tf.train.BytesList(value = [bytes(filename, 'utf-8') ])),\n",
    "            'image/encoded': _bytes_feature(img_bytes),\n",
    "            'image/height':tf.train.Feature(int64_list = tf.train.Int64List(value = [IMAGE_SIZES[1]])),\n",
    "            'image/width':tf.train.Feature(int64_list = tf.train.Int64List(value = [IMAGE_SIZES[0]])),\n",
    "            'image/channels':tf.train.Feature(int64_list = tf.train.Int64List(value = [3])),\n",
    "            'image/format': tf.train.Feature(bytes_list = tf.train.BytesList(value = [bytes('jpeg', 'utf-8') ])),\n",
    "            'image/object/bbox/xmin': tf.train.Feature(float_list = tf.train.FloatList(value = x_min)),\n",
    "            'image/object/bbox/ymin': tf.train.Feature(float_list = tf.train.FloatList(value = y_min)),\n",
    "            'image/object/bbox/xmax': tf.train.Feature(float_list = tf.train.FloatList(value = x_max)),\n",
    "            'image/object/bbox/ymax': tf.train.Feature(float_list = tf.train.FloatList(value = y_max)),\n",
    "            'image/object/class/text': tf.train.Feature(bytes_list = tf.train.BytesList(value = label_texts)),\n",
    "            'image/object/class/label': tf.train.Feature(int64_list = tf.train.Int64List(value = labels)),\n",
    "        })\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augument_data(imgdata_path, curr_filename, curr_bounding_boxes):\n",
    "        img_path =os.path.join(imgdata_path, curr_filename)\n",
    "\n",
    "        bbxArr = []\n",
    "        for i in curr_bounding_boxes:\n",
    "            bbxArr.append([*i[:4]])\n",
    "\n",
    "        with tf.io.gfile.GFile(img_path, 'rb') as fid:\n",
    "            img_bytes = fid.read()\n",
    "\n",
    "            img_tensor, new_bbxs, bbxs_with_label = decode_img(img_bytes, bbxs=bbxArr)\n",
    "            feature_output = [create_future(curr_filename, new_bbxs, img_tensor)]\n",
    "\n",
    "            for _ in range(4):\n",
    "                tmp_img_tensor, tmp_bbxs = random_augument(img_tensor, bbxs_with_label)\n",
    "                feature_output.append(create_future(curr_filename, tmp_bbxs, tmp_img_tensor))\n",
    "\n",
    "            return feature_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDataSet(labels_path, imgdata_path, output_path, limit = -1):\n",
    "    with open(labels_path) as f:\n",
    "        lines = f.readlines()\n",
    "        curr_bounding_boxes = []\n",
    "        curr_filename = \"\"\n",
    "        first = True\n",
    "        counter = 1\n",
    "        prevWasBegin = False\n",
    "        with tf.io.TFRecordWriter(output_path) as writer:\n",
    "            for line in lines:\n",
    "                if limit != -1 and counter >= limit: break\n",
    "\n",
    "                line = line.replace(\"\\n\", \"\")\n",
    "                if prevWasBegin:\n",
    "                    prevWasBegin = False\n",
    "                    continue\n",
    "                \n",
    "                if \"/\" in line:\n",
    "                    if not first:\n",
    "                        curr_augumented_features =  augument_data(imgdata_path, curr_filename, curr_bounding_boxes)\n",
    "                        for feature in curr_augumented_features:\n",
    "                            writer.write(tf.train.Example.SerializeToString(feature))\n",
    "                            \n",
    "                        curr_bounding_boxes = []\n",
    "                        counter +=1\n",
    "                    curr_filename = line\n",
    "                    prevWasBegin = True\n",
    "                    continue\n",
    "                \n",
    "                first = False\n",
    "\n",
    "                line = line.strip()\n",
    "                split = line.split(\" \")\n",
    "                next = []\n",
    "\n",
    "                for num in split:\n",
    "                    next.append(int(num))\n",
    "\n",
    "                curr_bounding_boxes.append(next)\n",
    "        print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3226\n"
     ]
    }
   ],
   "source": [
    "#create validation dataset\n",
    "convertToDataSet(VALIDATION_LABELS, VALIDATION_IMAGES, OUTPUT_VALIDATION_TFRECORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12880\n"
     ]
    }
   ],
   "source": [
    "#create train dataset\n",
    "convertToDataSet(TRAIN_LABELS, TRAIN_IMAGES, OUTPUT_TRAIN_TFRECORD)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24c78f2902c3eaca8402099206b187d2e0c79b256a5a127d981db2350636b3f9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tf': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
