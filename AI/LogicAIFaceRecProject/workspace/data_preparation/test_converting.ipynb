{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import tensorflow as tf\n",
    "os.chdir('..')\n",
    "join = os.path.join(os.getcwd(), '_global')\n",
    "sys.path.extend([join])\n",
    "from _global.config import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "import cv2\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_DESCRIPTION = {\n",
    "    'filename': tf.io.VarLenFeature(tf.string),\n",
    "    'shape' : tf.io.FixedLenFeature([3], tf.int64),\n",
    "    'image' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'bbxs' : tf.io.VarLenFeature(tf.int64), \n",
    "    'faces' : tf.io.FixedLenFeature([1], tf.int64),\n",
    "}\n",
    "\n",
    "bbx_params = A.BboxParams('albumentations', min_area=1, min_visibility=-2, label_fields=None, check_each_transform=False)\n",
    "transform = A.Compose([\n",
    "    A.Resize(IMAGE_SIZES[0], IMAGE_SIZES[1]),\n",
    "], bbox_params = bbx_params)\n",
    "\n",
    "def prepare_bbxs(bbxs, width, height):\n",
    "    bbx_to_transform = []\n",
    "    for bbx in bbxs:\n",
    "        temp = bbx\n",
    "        temp[2] += temp[0]\n",
    "        temp[2] /= width\n",
    "        \n",
    "        temp[3] += temp[1]\n",
    "        temp[3] /= height\n",
    "\n",
    "        temp[0] /= width\n",
    "        temp[1] /= height\n",
    "\n",
    "        if temp[0] > 1 or temp[1] > 1 or temp[2] > 1 or temp[2] <= temp[0] or temp[3] > 1 or temp[3] <= temp[1]:\n",
    "            continue\n",
    "        \n",
    "        temp2 = temp.copy()\n",
    "        # temp2[0] = temp[1]\n",
    "        # temp2[1] = temp[0]\n",
    "        # temp2[2] = temp[3]\n",
    "        # temp2[3] = temp[2]\n",
    "\n",
    "        temp2.append('x')\n",
    "\n",
    "        bbx_to_transform.append(temp2)\n",
    "    return bbx_to_transform\n",
    "\n",
    "\n",
    "def decode_img(img, bbxs = [], resize=False):\n",
    "    image = tf.image.decode_jpeg(img , channels=3)\n",
    "\n",
    "    height, width, channels = image.shape\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    bbxs_return = []\n",
    "    if resize:\n",
    "        image = tf.image.resize(image, [IMAGE_SIZES[0], IMAGE_SIZES[1]])\n",
    "        image = image.numpy()\n",
    "        bbx_to_transform = prepare_bbxs(bbxs, width, height)\n",
    "        if(len(bbxs) > 0):\n",
    "            transformed = transform(image=image, bboxes=bbx_to_transform)\n",
    "            bbxs_temp = transformed['bboxes']\n",
    "\n",
    "            for bbx in bbxs_temp:\n",
    "                bbxs_return.append([\n",
    "                     round(bbx[0] * IMAGE_SIZES[0]),\n",
    "                     round(bbx[1] * IMAGE_SIZES[1]),\n",
    "                     round((bbx[2] - bbx[0]) * IMAGE_SIZES[0]),\n",
    "                     round((bbx[3] - bbx[1]) * IMAGE_SIZES[1])\n",
    "                ])\n",
    "        \n",
    "        else: \n",
    "            transformed = transform(image=image)\n",
    "            bbxs_return.append([])\n",
    "\n",
    "        image = tf.convert_to_tensor(transformed['image'])\n",
    "    else:\n",
    "        return image\n",
    "    return image, bbxs_return\n",
    "\n",
    "\n",
    "def parse_function(example_proto):\n",
    "  # Parse the input `tf.Example` proto using the dictionary above.\n",
    "  example = tf.io.parse_single_example(example_proto, FEATURE_DESCRIPTION)\n",
    "  image = decode_img(example['image'])\n",
    "  image = tf.cast(image, tf.uint8)\n",
    "  #   print(example['bbxs'])\n",
    "  bbxs = tf.cast(example['bbxs'], tf.int64)\n",
    "  print(tf.cast(example['filename'], tf.string))\n",
    "  if isinstance(bbxs, tf.SparseTensor):\n",
    "      bbxs = tf.sparse.to_dense(bbxs)\n",
    "      \n",
    "  return image, bbxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79, 15, 58, 53]]\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(INSTALLATION_PATH, \"test_scaled_down.jpeg\")\n",
    "src = os.path.join(TRAIN_IMAGES, \"0--Parade\\\\0_Parade_Parade_0_904.jpg\")\n",
    "\n",
    "with tf.io.gfile.GFile(src, 'rb') as fid:\n",
    "    image_bytes = fid.read()\n",
    "    image_bytes, bbxs = decode_img(image_bytes, bbxs=[[361, 98, 263, 339]], resize=True)\n",
    "    print(bbxs)\n",
    "    image_bytes = tf.cast(image_bytes, tf.uint8)\n",
    "    tf.io.write_file(path, tf.io.encode_jpeg(image_bytes))\n",
    "\n",
    "    with tf.io.gfile.GFile(path, 'rb') as fid2:\n",
    "        img_tensor = decode_img(fid2.read())\n",
    "        img_tensor = tf.cast(img_tensor, tf.uint8)\n",
    "        # img_tensor = tf.io.encode_jpeg(img_tensor)\n",
    "\n",
    "        img = Image.fromarray(img_tensor.numpy())\n",
    "        \n",
    "        img.show()\n",
    "        # plt.imshow(img_tensor.numpy())\n",
    "\n",
    "    # img = mpimg.imread(path)\n",
    "    # plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_bounding_boxes_from_tf_record(temppath, window_name):\n",
    "    c = 0\n",
    "    for record in tf.compat.v1.python_io.tf_record_iterator(OUTPUT_TRAIN_TFRECORD):\n",
    "        c+=1\n",
    "        if c < 2: continue\n",
    "        image, _bbxs = parse_function(record)\n",
    "        image = tf.cast(image, tf.uint8)\n",
    "        \n",
    "        _bbxs = _bbxs.numpy()\n",
    "        bbxs =  [_bbxs[x:x+4] for x in range(0, len(_bbxs), 4)]\n",
    "\n",
    "        tf.io.write_file(tempath, tf.io.encode_jpeg(image))\n",
    "\n",
    "        img = cv2.imread(tempath)\n",
    "\n",
    "        for bbx in bbxs:\n",
    "            x1, y1 = bbx[0], bbx[1]\n",
    "\n",
    "            if x1 == 0 and y1 == 0:\n",
    "                continue\n",
    "\n",
    "            x2, y2 = bbx[0] + bbx[2], bbx[1] + bbx[3]\n",
    "            print(bbx)\n",
    "\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 1)\n",
    "\n",
    "        cv2.imshow(window_name, img)\n",
    "\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        # img.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor([[0]], shape=(1, 1), dtype=int64), values=tf.Tensor([b'0--Parade/0_Parade_Parade_0_904.jpg'], shape=(1,), dtype=string), dense_shape=tf.Tensor([1], shape=(1,), dtype=int64))\n",
      "[79 15 58 53]\n"
     ]
    }
   ],
   "source": [
    "tempath = os.path.join(INSTALLATION_PATH, \"scaled_down_2223.jpg\")\n",
    "window_name = \"xxx\"\n",
    "draw_bounding_boxes_from_tf_record(tempath, window_name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24c78f2902c3eaca8402099206b187d2e0c79b256a5a127d981db2350636b3f9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tf': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
