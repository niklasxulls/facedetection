{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import tensorflow as tf\n",
    "os.chdir('..')\n",
    "join = os.path.join(os.getcwd(), '_global')\n",
    "sys.path.extend([join])\n",
    "from _global.config import *\n",
    "from _global.funcs import *\n",
    "from _global.bbx import *\n",
    "import tkinter\n",
    "import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from tensorflow.keras import *\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "import cv2\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def detect_fn(input_tensor, model):\n",
    "    image, shapes = model.preprocess(input_tensor)\n",
    "    prediction_dict = model.predict(image, shapes)\n",
    "    detections = model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_image(img_np, model, draw_bbxs=False):\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(img_np, 0), dtype=tf.float32)\n",
    "\n",
    "    prediction = detect_fn(input_tensor, model)\n",
    "\n",
    "    num_detections = int(prediction.pop('num_detections'))\n",
    "    prediction = {key: value[0, :num_detections].numpy()\n",
    "                for key, value in prediction.items()}\n",
    "\n",
    "\n",
    "    label_map = label_map_util.load_labelmap(LABEL_MAP_PATH)\n",
    "\n",
    "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=1, use_display_name=True)\n",
    "\n",
    "    category_index = label_map_util.create_category_index(categories)   \n",
    "\n",
    "    prediction['detection_classes'] = prediction['detection_classes'].astype(np.int64) +1\n",
    "\n",
    "    if not draw_bbxs:\n",
    "        return prediction\n",
    "\n",
    "    img_with_detections = img_np.copy()\n",
    "\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(img_with_detections,\n",
    "                                                        prediction['detection_boxes'],\n",
    "                                                        prediction['detection_classes'],\n",
    "                                                        prediction['detection_scores'],\n",
    "                                                        category_index,\n",
    "                                                        min_score_thresh=.5,\n",
    "                                                        agnostic_mode=False,\n",
    "                                                        use_normalized_coordinates=True\n",
    "                                                        )\n",
    "\n",
    "    return img_with_detections\n",
    "\n",
    "\n",
    "def predict_for_image_with_path(path, model):\n",
    "    image_np = np.array(Image.open(path))\n",
    "    \n",
    "    return predict_for_image(image_np, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbx(img, bbx, color=(255, 0, 0), thickness=1):\n",
    "    p1 = int(bbx[0]), int(bbx[1])\n",
    "    p2 = int(bbx[2]), int(bbx[3])\n",
    "    \n",
    "    cv2.rectangle(img, p1, p2,color, thickness)\n",
    "\n",
    "def draw_bbxs_on_image(img_tensor, bbxs, img_shape=(*IMAGE_SIZES, 3), bbxs_scaled_down=True, bbxs_are_ratio = True, window_name=\"default\"):\n",
    "    if not bbxs_scaled_down or bbxs_are_ratio:\n",
    "        if not bbxs_scaled_down:\n",
    "            x_ratio = img_shape / IMAGE_SIZES[0]\n",
    "            y_ratio = img_shape / IMAGE_SIZES[1]\n",
    "\n",
    "        if bbxs_are_ratio:\n",
    "            x_ratio = IMAGE_SIZES[0]\n",
    "            y_ratio = IMAGE_SIZES[1]\n",
    "\n",
    "\n",
    "        for bbx in bbxs:\n",
    "\n",
    "            bbx[0] *= x_ratio\n",
    "            bbx[2] *= x_ratio\n",
    "\n",
    "            bbx[1] *= y_ratio\n",
    "            bbx[3] *= y_ratio\n",
    "\n",
    "\n",
    "    img = img_tensor.numpy()\n",
    "\n",
    "    for bbx in bbxs:\n",
    "        draw_bbx(img, bbx)\n",
    "\n",
    "    cv2.imshow(window_name, img)\n",
    "    cv2.moveWindow(window_name, -1920, 0)\n",
    "    cv2.setWindowProperty(window_name, cv2.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "    while cv2.getWindowProperty(window_name, 0) >= 0:\n",
    "        k = cv2.waitKey(0)\n",
    "        if k == 27:\n",
    "            break\n",
    "        continue\n",
    "    \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbxs_from_tfrecord(tfrecord_path, record_number):\n",
    "    if not isinstance(tfrecord_path, list):\n",
    "        tfrecord_path = [tfrecord_path]\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        if i +1 != record_number:\n",
    "            continue\n",
    "        \n",
    "        curr = dataset[i][0]\n",
    "        image, bbxs = parse_function(curr)\n",
    "\n",
    "        draw_bbxs_on_image(image, bbxs, 'from_tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1f3998da940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(PIPELINE_CONFIG_PATH)\n",
    "configs = config_util.get_configs_from_pipeline_file(PIPELINE_CONFIG_PATH)\n",
    "model = model_builder.build(model_config=config['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=model) \n",
    "ckpt.restore(os.path.join(MODEL, 'ckpt-12')).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [67.77223   47.06517   16.923975  25.885923  50.304874  35.963966\n",
    "#   6.2854676 10.204706  41.274918  30.414097   4.0224295  7.105852\n",
    "#  37.16802   27.614225   3.1189811  5.787781  33.005714  24.588493\n",
    "#   2.2111108  4.368665 ]\n",
    "\n",
    "# [71.112305  49.371758  17.722971  27.159712  52.783493  37.700424\n",
    "#   6.570285  10.685776  43.320473  31.924595   4.2354403  7.480593\n",
    "#  38.9796    28.967466   3.2910812  6.0731983 34.608833  25.760878\n",
    "#   2.3060017  4.58374  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(TEST_IMAGES, \"49--Greeting\\\\49_Greeting_peoplegreeting_49_2.jpg\")\n",
    "path = os.path.join(TRAIN_IMAGES, \"1--Handshaking\\\\1_Handshaking_Handshaking_1_82.jpg\")\n",
    "img_np_with_detections = predict_for_image_with_path(path, model)\n",
    "# test = tf.squeeze(test, [0])\n",
    "# test = tf.cast(test, dtype=tf.uint8)\n",
    "# f_shape = 1\n",
    "# for shape in test.shape:\n",
    "#     f_shape *= shape\n",
    "# plt.imshow(cv2.cvtColor(img_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "# plt.show()\n",
    "   \n",
    "\n",
    "\n",
    "img = tf.image.encode_jpeg(img_np_with_detections)\n",
    "tf.io.write_file(os.path.join(INSTALLATION_PATH, \"test123443.jpeg\"), img)\n",
    "\n",
    "\n",
    "# test = tf.reshape(test, f_shape)\n",
    "# test = test.numpy()\n",
    "# draw_bbxs_on_image(img_tensor, bbxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    image_np_with_detections = predict_for_image(model,np.array(frame), True)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (width, height)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_bbx(bbxs, scores):\n",
    "    _max = -1\n",
    "    index = 0\n",
    "    for i in range(len(bbxs)):\n",
    "        if scores[i] > _max:\n",
    "            _max = scores[i]\n",
    "            index = i\n",
    "    return bbxs[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_faces_and_create_json():\n",
    "    input_path = os.path.join(INSTALLATION_PATH, \"Niklas_Faces\")\n",
    "    output_path = os.path.join(INSTALLATION_PATH, \"faces.json\")\n",
    "    imgs = [(os.path.join(input_path, f),cv2.imread(os.path.join(input_path, f))) for f in os.listdir(input_path)]\n",
    "    shape = imgs[0][1].shape\n",
    "    bbxs = []\n",
    "    _json = \"[\\r\\n\"\n",
    "    for i in range(len(imgs)):\n",
    "        if i > 0:\n",
    "            _json +=\",\"\n",
    "        filename, img = imgs[i]\n",
    "        prediction = predict_for_image(np.array(img), model)\n",
    "        prediction['detection_boxes'] = prediction['detection_boxes'].tolist()\n",
    "        for x in prediction['detection_boxes']:\n",
    "            x[0] *= shape[1]\n",
    "            x[1] *= shape[0]\n",
    "            x[2] *= shape[1]\n",
    "            x[3] *= shape[0]\n",
    "\n",
    "        best_bbx = get_best_bbx(prediction['detection_boxes'],prediction['detection_scores'])\n",
    "        best_bbx_json = Bbx(filename,*best_bbx)\n",
    "        _json += \"\\r\\n\" + best_bbx_json.to_json()\n",
    "    _json += \"]\"\n",
    "    with open(output_path,'w') as f:\n",
    "        f.write(_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_extract_face(img, model, output_path_with_filename=None):\n",
    "    shape = img.shape\n",
    "    prediction = predict_for_image(np.array(img), model)\n",
    "\n",
    "    best_bbx = get_best_bbx(prediction['detection_boxes'],prediction['detection_scores'])\n",
    "    best_bbx[0]*= shape[0]\n",
    "    best_bbx[1] *= shape[1]\n",
    "    best_bbx[2] *= shape[0]\n",
    "    best_bbx[3] *= shape[1]\n",
    "\n",
    "    face = img[int(shape[0] -best_bbx[2]):int(shape[0] -best_bbx[0]), int(best_bbx[1]):int(best_bbx[3])]\n",
    "    face = cv2.resize(face, (RECOG_IMAGE_SIZES[1], RECOG_IMAGE_SIZES[0]))\n",
    "    if output_path_with_filename == None:\n",
    "        return face\n",
    "    cv2.imwrite(output_path_with_filename,face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_extract_faces(input_path, output_path):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "    imgs = [(f ,cv2.imread(os.path.join(input_path, f))) for f in os.listdir(input_path)]\n",
    "    for i in range(len(imgs)):\n",
    "        filename, img = imgs[i]\n",
    "        find_and_extract_face(img, model, os.path.join(output_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    input_path = os.path.join(INSTALLATION_PATH, \"Kek_Faces\")\n",
    "    output_path = os.path.join(INSTALLATION_PATH, \"Kek_Cropped_Faces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_and_extract_faces(input_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24c78f2902c3eaca8402099206b187d2e0c79b256a5a127d981db2350636b3f9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tf': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
