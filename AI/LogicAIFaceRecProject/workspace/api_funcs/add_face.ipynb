{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import *\n",
    "import numpy as np\n",
    "import sys, os\n",
    "os.chdir('..')\n",
    "join = os.path.join(os.getcwd(), '_global')\n",
    "sys.path.extend([join])\n",
    "from _global.config import *\n",
    "from _global.funcs import *\n",
    "from _global.bbx import *\n",
    "from _global.recognition import *\n",
    "sys.path.extend([RESEARCH])\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.builders import model_builder\n",
    "from IPython import get_ipython\n",
    "import cv2 \n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "import urllib.request\n",
    "ipython = get_ipython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_and_get_dataset(img_url_paths, label_name, label_num):\n",
    "    t = os.path.join(INSTALLATION_PATH, \"TEMP_IMGS\")\n",
    "    if os.path.exists(t):\n",
    "        os.rmdir(t)\n",
    "    os.mkdir(t)\n",
    "\n",
    "    for i in range(len(img_url_paths)):\n",
    "         urllib.request.urlretrieve(img_url_paths[i], os.path.join(t, \"temp{}.jpg\".format(i)))\n",
    "         \n",
    "    temp_tfrecord_name = os.path.join(t, \"temp.tfrecord\")\n",
    "    parse_images(temp_tfrecord_name, t, label_name, label_num)\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset([temp_tfrecord_name])\n",
    "    dataset = dataset.map(parse_fn)\n",
    "    dataset = dataset.batch(FACE_RECOG_BATCH_SIZE)\n",
    "\n",
    "    os.rmdir(t)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_face_added(model, face_name, img_url_paths, override_existing=True):\n",
    "    curr_classes = model.layers[:].pop().output_shape[-1]\n",
    "    last_dense_before_output_neurons = model.layers[:][len(model.layers)-1]\n",
    "    \n",
    "    prev_output_layer = model.layers.pop()\n",
    "    prev_weights = prev_output_layer.get_weights()[0]\n",
    "    bias = prev_weights[1]\n",
    "    sum = 1\n",
    "    for shape in prev_weights.shape:\n",
    "        sum *= shape\n",
    "    prev_weights = np.reshape(prev_weights, (sum))\n",
    "    prev_weights = np.array(prev_weights.tolist().append(bias))\n",
    "    curr_classes += 1\n",
    "    for _ in range(last_dense_before_output_neurons):\n",
    "        prev_weights = np.insert(prev_weights, 0, 0.0, 0)\n",
    "    \n",
    "    new_init_weights = tf.constant_initializer(prev_weights)\n",
    "    new_output_layer = layers.Dense(curr_classes, activation='softmax', kernel_initializer=new_init_weights) \n",
    "    model.add(new_output_layer)\n",
    "\n",
    "    dataset = prepare_and_get_dataset(img_url_paths, face_name, curr_classes)\n",
    "    model.fit(dataset, epochs=3)\n",
    "\n",
    "    extend_label_map(curr_classes +1, face_name)\n",
    "\n",
    "    if override_existing:\n",
    "        models.save_model(model, FACES_RECOG)\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
