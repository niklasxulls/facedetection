{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_addons'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mextend([join])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_global\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_global\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfuncs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_global\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbbx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_global\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecognition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\niklas\\Desktop\\AI\\Projekte\\Face_Recognition_Ullsperger\\LogicAIFaceRecProject\\workspace\\_global\\funcs.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mA\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfa\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_util\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_addons'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import *\n",
    "import numpy as np\n",
    "import sys, os\n",
    "os.chdir('..')\n",
    "join = os.path.join(os.getcwd(), '_global')\n",
    "sys.path.extend([join])\n",
    "from _global.config import *\n",
    "from _global.funcs import *\n",
    "from _global.bbx import *\n",
    "from _global.recognition import *\n",
    "sys.path.extend([RESEARCH])\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.builders import model_builder\n",
    "from IPython import get_ipython\n",
    "import cv2 \n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "ipython = get_ipython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_face(frame, localizer, detector):\n",
    "    face, best_bbx = find_and_extract_face(localizer, frame, None, True)\n",
    "    face = tf.convert_to_tensor(face,dtype=tf.uint8)\n",
    "    face = tf.expand_dims(face, 0)\n",
    "    label = detector.predict(face)\n",
    "    label = np.squeeze(label,axis=0)\n",
    "    max_label = 0\n",
    "    for i in range(len(label)):\n",
    "        if label[i] >= label[max_label]:\n",
    "            max_label = i\n",
    "\n",
    "    #max label +2 because now we work with indecies because we have to work with ids that start from 1 and id 1 is unknown\n",
    "    if label[max_label] < .60:\n",
    "        max_label = 1\n",
    "    else: max_label +=2\n",
    "\n",
    "    label_map = label_map_util.load_labelmap(FACES_RECOG_LABEL_MAP)\n",
    "\n",
    "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=max_classes+1, use_display_name=True)\n",
    "\n",
    "    category_index = label_map_util.create_category_index(categories)   \n",
    "\n",
    "    x = np.array(1.0)\n",
    "\n",
    "    img_with_bbxs = viz_utils.visualize_boxes_and_labels_on_image_array(frame,\n",
    "                                                        boxes=np.array([best_bbx]),\n",
    "                                                        classes=np.array([max_label]),\n",
    "                                                        scores=np.array([1.0]),\n",
    "                                                        category_index=category_index,\n",
    "                                                        agnostic_mode=False,\n",
    "                                                        skip_scores=True\n",
    "                                                    )\n",
    "    \n",
    "    print(label)\n",
    "    return img_with_bbxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recog = models.load_model(OUTPUT_FACES_RECOG)\n",
    "\n",
    "config = config_util.get_configs_from_pipeline_file(PIPELINE_CONFIG_PATH)\n",
    "configs = config_util.get_configs_from_pipeline_file(PIPELINE_CONFIG_PATH)\n",
    "bbx_localizer = model_builder.build(model_config=config['model'], is_training=False)\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=bbx_localizer) \n",
    "ckpt.restore(os.path.join(MODEL, 'ckpt-12')).expect_partial()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == False:\n",
    "        continue\n",
    "\n",
    "    image_np_with_detections = predict_face(frame, bbx_localizer, face_recog)\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (width, height)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24c78f2902c3eaca8402099206b187d2e0c79b256a5a127d981db2350636b3f9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tf': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
