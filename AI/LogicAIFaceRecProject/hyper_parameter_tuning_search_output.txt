101/101 [==============================] - 75s 577ms/step - loss: 306913509376.0000 - accuracy: 7.5101e-07
optimizer: RMSprop, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [7.51011782540445e-07], loss: [306913509376.0], 

101/101 [==============================] - 77s 585ms/step - loss: 450043846072005210144768.0000 - accuracy: 0.0000e+00
optimizer: RMSprop, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.0], loss: [4.500438460720052e+23], 

101/101 [==============================] - 77s 586ms/step - loss: 368.1945 - accuracy: 0.0000e+00
optimizer: RMSprop, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.0], loss: [368.1945495605469], 

101/101 [==============================] - 76s 575ms/step - loss: 578604171264.0000 - accuracy: 0.0000e+00
optimizer: RMSprop, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [0.0], loss: [578604171264.0], 

101/101 [==============================] - 77s 574ms/step - loss: 388254495213279023988736.0000 - accuracy: 0.0000e+00
optimizer: RMSprop, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.0], loss: [3.88254495213279e+23], 

101/101 [==============================] - 75s 561ms/step - loss: 364.7386 - accuracy: 0.0000e+00
optimizer: RMSprop, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.0], loss: [364.7386474609375], 

101/101 [==============================] - 76s 560ms/step - loss: 584996683776.0000 - accuracy: 0.0000e+00
optimizer: RMSprop, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [0.0], loss: [584996683776.0], 

101/101 [==============================] - 77s 561ms/step - loss: 387190600866106036977664.0000 - accuracy: 0.0000e+00
optimizer: RMSprop, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.0], loss: [3.8719060086610604e+23], 

101/101 [==============================] - 77s 561ms/step - loss: 368.4169 - accuracy: 0.0000e+00
optimizer: RMSprop, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.0], loss: [368.4168701171875], 

101/101 [==============================] - 78s 560ms/step - loss: 583353171968.0000 - accuracy: 0.0000e+00
optimizer: RMSprop, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [0.0], loss: [583353171968.0], 

101/101 [==============================] - 78s 563ms/step - loss: 386217823346594009841664.0000 - accuracy: 7.1148e-07
optimizer: RMSprop, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [7.114848585842992e-07], loss: [3.86217823346594e+23], 

101/101 [==============================] - 78s 571ms/step - loss: 364.6331 - accuracy: 0.0000e+00
optimizer: RMSprop, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.0], loss: [364.6331481933594], 

101/101 [==============================] - 79s 565ms/step - loss: 582708690944.0000 - accuracy: 0.0000e+00
optimizer: RMSprop, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [0.0], loss: [582708690944.0], 

101/101 [==============================] - 78s 560ms/step - loss: 385228400522859221352448.0000 - accuracy: 0.0000e+00
optimizer: RMSprop, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.0], loss: [3.852284005228592e+23], 

101/101 [==============================] - 78s 563ms/step - loss: 368.3506 - accuracy: 0.0000e+00
optimizer: RMSprop, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.0], loss: [368.3505859375], 

101/101 [==============================] - 75s 544ms/step - loss: 142936326144.0000 - accuracy: 0.0000e+00
optimizer: Adadelta, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [0.0], loss: [142936326144.0], 

101/101 [==============================] - 76s 548ms/step - loss: 1842191187847413760.0000 - accuracy: 0.0000e+00
optimizer: Adadelta, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.0], loss: [1.8421911878474138e+18], 

101/101 [==============================] - 77s 551ms/step - loss: 35.3388 - accuracy: 0.0000e+00
Epoch 1/2
101/101 [==============================] - 77s 563ms/step - loss: 35.3388 - accuracy: 0.0000e+00
Epoch 2/2
101/101 [==============================] - 76s 554ms/step - loss: 35.3388 - accuracy: 0.0000e+00
Epoch 1/3
101/101 [==============================] - 76s 550ms/step - loss: 35.3376 - accuracy: 0.0000e+00
Epoch 2/3
101/101 [==============================] - 76s 559ms/step - loss: 35.1057 - accuracy: 0.0000e+00
Epoch 3/3
101/101 [==============================] - 77s 559ms/step - loss: 32.4802 - accuracy: 0.0000e+00
optimizer: Adadelta, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.0, 0.0, 0.0], loss: [35.33759307861328, 35.105674743652344, 32.48020935058594], 

101/101 [==============================] - 77s 554ms/step - loss: 3650515.0000 - accuracy: 0.0000e+00
optimizer: Adadelta, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [0.0], loss: [3650515.0], 

101/101 [==============================] - 78s 553ms/step - loss: 987528911107653632.0000 - accuracy: 0.0000e+00
optimizer: Adadelta, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.0], loss: [9.875289111076536e+17], 

101/101 [==============================] - 78s 547ms/step - loss: 211.0837 - accuracy: 0.0000e+00
optimizer: Adadelta, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.0], loss: [211.0836639404297], 

101/101 [==============================] - 78s 550ms/step - loss: 859444096.0000 - accuracy: 0.0000e+00
optimizer: Adadelta, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [0.0], loss: [859444096.0], 

101/101 [==============================] - 79s 561ms/step - loss: 502541547640717312.0000 - accuracy: 0.0000e+00
optimizer: Adadelta, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.0], loss: [5.025415476407173e+17], 

101/101 [==============================] - 79s 557ms/step - loss: 212.3395 - accuracy: 0.0000e+00
optimizer: Adadelta, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.0], loss: [212.33950805664062], 

101/101 [==============================] - 79s 552ms/step - loss: 840480128.0000 - accuracy: 0.0000e+00
optimizer: Adadelta, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [0.0], loss: [840480128.0], 

101/101 [==============================] - 81s 569ms/step - loss: 434562729424977920.0000 - accuracy: 0.0000e+00
optimizer: Adadelta, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.0], loss: [4.345627294249779e+17], 

101/101 [==============================] - 80s 562ms/step - loss: 208.7163 - accuracy: 0.0000e+00
optimizer: Adadelta, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.0], loss: [208.7162628173828], 

101/101 [==============================] - 80s 572ms/step - loss: 792870080.0000 - accuracy: 0.0000e+00
optimizer: Adadelta, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [0.0], loss: [792870080.0], 

101/101 [==============================] - 80s 559ms/step - loss: 395958429497163776.0000 - accuracy: 0.0000e+00
optimizer: Adadelta, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.0], loss: [3.959584294971638e+17], 

101/101 [==============================] - 80s 564ms/step - loss: 208.0300 - accuracy: 0.0000e+00
optimizer: Adadelta, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.0], loss: [208.02996826171875], 

101/101 [==============================] - 80s 554ms/step - loss: 25140424704.0000 - accuracy: 0.0000e+00
optimizer: Adagrad, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [0.0], loss: [25140424704.0], 

101/101 [==============================] - 80s 551ms/step - loss: 72953765327778390999040.0000 - accuracy: 1.5514e-06
optimizer: Adagrad, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [1.5514322058152175e-06], loss: [7.295376532777839e+22], 

101/101 [==============================] - 80s 549ms/step - loss: 54.1034 - accuracy: 1.0978e-07
Epoch 1/2
101/101 [==============================] - 79s 560ms/step - loss: 54.1034 - accuracy: 6.0989e-08
Epoch 2/2
101/101 [==============================] - 81s 572ms/step - loss: 54.1035 - accuracy: 6.0989e-08
Epoch 1/3
101/101 [==============================] - 82s 586ms/step - loss: 54.1034 - accuracy: 7.9285e-08
Epoch 2/3
101/101 [==============================] - 80s 565ms/step - loss: 54.1034 - accuracy: 1.1588e-07
Epoch 3/3
101/101 [==============================] - 80s 557ms/step - loss: 54.1035 - accuracy: 7.9285e-08
optimizer: Adagrad, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [7.928547063329461e-08, 1.1587876969088029e-07, 7.928547063329461e-08], loss: [54.10344696044922, 54.103424072265625, 54.10348892211914], 

101/101 [==============================] - 84s 579ms/step - loss: 72809.1094 - accuracy: 8.5384e-08
optimizer: Adagrad, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [8.538435736227257e-08], loss: [72809.109375], 

101/101 [==============================] - 83s 569ms/step - loss: 640632704.0000 - accuracy: 0.0000e+00
optimizer: Adagrad, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.0], loss: [640632704.0], 

101/101 [==============================] - 82s 553ms/step - loss: 53.2028 - accuracy: 0.0000e+00
Epoch 1/2
101/101 [==============================] - 80s 552ms/step - loss: 53.2028 - accuracy: 0.0000e+00
Epoch 2/2
101/101 [==============================] - 80s 554ms/step - loss: 53.2028 - accuracy: 0.0000e+00
Epoch 1/3
101/101 [==============================] - 80s 555ms/step - loss: 53.2028 - accuracy: 0.0000e+00
Epoch 2/3
101/101 [==============================] - 82s 569ms/step - loss: 53.2028 - accuracy: 0.0000e+00
Epoch 3/3
101/101 [==============================] - 81s 568ms/step - loss: 53.2028 - accuracy: 0.0000e+00
optimizer: Adagrad, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.0, 0.0, 0.0], loss: [53.202781677246094, 53.2027702331543, 53.20276641845703], 

101/101 [==============================] - 83s 554ms/step - loss: 72782.3438 - accuracy: 0.0000e+00
optimizer: Adagrad, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [0.0], loss: [72782.34375], 

101/101 [==============================] - 83s 557ms/step - loss: 467629152.0000 - accuracy: 0.0000e+00
optimizer: Adagrad, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.0], loss: [467629152.0], 

101/101 [==============================] - 86s 585ms/step - loss: 52.9268 - accuracy: 1.7687e-07
Epoch 1/2
101/101 [==============================] - 84s 584ms/step - loss: 52.9267 - accuracy: 9.7582e-08
Epoch 2/2
101/101 [==============================] - 84s 584ms/step - loss: 52.9268 - accuracy: 8.5384e-08
Epoch 1/3
101/101 [==============================] - 84s 581ms/step - loss: 52.9268 - accuracy: 3.0494e-08
Epoch 2/3
101/101 [==============================] - 84s 581ms/step - loss: 52.9268 - accuracy: 6.7088e-08
Epoch 3/3
101/101 [==============================] - 90s 587ms/step - loss: 52.9267 - accuracy: 3.6593e-08
optimizer: Adagrad, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [3.049441232860772e-08, 6.70877113861934e-08, 3.6593295504872e-08], loss: [52.9267692565918, 52.926753997802734, 52.9267463684082], 

101/101 [==============================] - 86s 580ms/step - loss: 73028.2891 - accuracy: 3.6593e-08
optimizer: Adagrad, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [3.6593295504872e-08], loss: [73028.2890625], 

101/101 [==============================] - 87s 588ms/step - loss: 407684736.0000 - accuracy: 0.0000e+00
optimizer: Adagrad, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.0], loss: [407684736.0], 

101/101 [==============================] - 89s 601ms/step - loss: 52.7035 - accuracy: 6.0989e-08
Epoch 1/2
101/101 [==============================] - 86s 586ms/step - loss: 52.7035 - accuracy: 4.8791e-08
Epoch 2/2
101/101 [==============================] - 86s 589ms/step - loss: 52.7035 - accuracy: 4.2692e-08
Epoch 1/3
101/101 [==============================] - 88s 605ms/step - loss: 52.7035 - accuracy: 9.7582e-08
Epoch 2/3
101/101 [==============================] - 113s 857ms/step - loss: 52.7035 - accuracy: 4.2692e-08
Epoch 3/3
101/101 [==============================] - 115s 865ms/step - loss: 52.7035 - accuracy: 1.0978e-07
optimizer: Adagrad, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [9.758212371480113e-08, 4.2692178681136284e-08, 1.0977989006732969e-07], loss: [52.70353698730469, 52.703514099121094, 52.70353698730469], 

101/101 [==============================] - 105s 761ms/step - loss: 73693.2266 - accuracy: 9.1483e-08
optimizer: Adagrad, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [9.148323698582317e-08], loss: [73693.2265625], 

101/101 [==============================] - 104s 749ms/step - loss: 383943264.0000 - accuracy: 0.0000e+00
optimizer: Adagrad, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.0], loss: [383943264.0], 

101/101 [==============================] - 104s 751ms/step - loss: 52.5043 - accuracy: 8.5384e-08
Epoch 1/2
101/101 [==============================] - 102s 750ms/step - loss: 52.5043 - accuracy: 4.2692e-08
Epoch 2/2
101/101 [==============================] - 103s 751ms/step - loss: 52.5043 - accuracy: 1.8297e-08
Epoch 1/3
101/101 [==============================] - 102s 751ms/step - loss: 52.5043 - accuracy: 4.2692e-08
Epoch 2/3
101/101 [==============================] - 103s 744ms/step - loss: 52.5043 - accuracy: 7.3187e-08
Epoch 3/3
101/101 [==============================] - 101s 742ms/step - loss: 52.5042 - accuracy: 6.7088e-08
optimizer: Adagrad, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [4.2692178681136284e-08, 7.3186591009744e-08, 6.70877113861934e-08], loss: [52.504310607910156, 52.504268646240234, 52.50424575805664], 

101/101 [==============================] - 105s 746ms/step - loss: 1703458897920.0000 - accuracy: 1.9763e-07
optimizer: Adamax, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [1.976346766241477e-07], loss: [1703458897920.0], 

101/101 [==============================] - 105s 747ms/step - loss: 217284115690581655552.0000 - accuracy: 1.8775e-07
optimizer: Adamax, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [1.8775294563511125e-07], loss: [2.1728411569058166e+20], 

101/101 [==============================] - 105s 749ms/step - loss: 121.7404 - accuracy: 0.0000e+00
optimizer: Adamax, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.0], loss: [121.74037170410156], 

101/101 [==============================] - 105s 746ms/step - loss: 6877163.5000 - accuracy: 0.0000e+00
optimizer: Adamax, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [0.0], loss: [6877163.5], 

101/101 [==============================] - 106s 747ms/step - loss: 3392621248512.0000 - accuracy: 7.9054e-08
optimizer: Adamax, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [7.90538692285736e-08], loss: [3392621248512.0], 

101/101 [==============================] - 106s 749ms/step - loss: 73.0668 - accuracy: 0.0000e+00
optimizer: Adamax, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.0], loss: [73.06683349609375], 

101/101 [==============================] - 106s 747ms/step - loss: 200356.1875 - accuracy: 0.0000e+00
optimizer: Adamax, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [0.0], loss: [200356.1875], 

101/101 [==============================] - 107s 749ms/step - loss: 3730689536.0000 - accuracy: 0.2018
optimizer: Adamax, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.20181241631507874], loss: [3730689536.0], 

101/101 [==============================] - 108s 749ms/step - loss: 33.7295 - accuracy: 0.9938
Epoch 1/2
101/101 [==============================] - 105s 751ms/step - loss: 34.4305 - accuracy: 0.9938
Epoch 2/2
101/101 [==============================] - 106s 751ms/step - loss: 34.4305 - accuracy: 0.9938
Epoch 1/3
101/101 [==============================] - 106s 752ms/step - loss: 34.4305 - accuracy: 0.9938
Epoch 2/3
101/101 [==============================] - 106s 752ms/step - loss: 34.4305 - accuracy: 0.9938
Epoch 3/3
101/101 [==============================] - 106s 752ms/step - loss: 34.4305 - accuracy: 0.9938
optimizer: Adamax, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.9937779307365417, 0.9937859773635864, 0.993773877620697], loss: [34.43051528930664, 34.430503845214844, 34.430519104003906], 

101/101 [==============================] - 108s 751ms/step - loss: 3481.9810 - accuracy: 0.9938
optimizer: Adamax, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [0.9937775135040283], loss: [3481.98095703125], 

101/101 [==============================] - 109s 752ms/step - loss: 4055781343232.0000 - accuracy: 0.0198
optimizer: Adamax, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.01979506015777588], loss: [4055781343232.0], 

101/101 [==============================] - 109s 752ms/step - loss: 106.3626 - accuracy: 0.0000e+00
optimizer: Adamax, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.0], loss: [106.36259460449219], 

101/101 [==============================] - 109s 753ms/step - loss: 2455174.5000 - accuracy: 0.0000e+00
optimizer: Adamax, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [0.0], loss: [2455174.5], 

101/101 [==============================] - 110s 751ms/step - loss: 9177712820224.0000 - accuracy: 0.0099
optimizer: Adamax, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.009898819029331207], loss: [9177712820224.0], 

101/101 [==============================] - 111s 751ms/step - loss: 91.7963 - accuracy: 0.0000e+00
optimizer: Adamax, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.0], loss: [91.79629516601562], 

101/101 [==============================] - 119s 835ms/step - loss: 2937588.5000 - accuracy: 2.2440e-04
optimizer: Ftrl, learning_rate: 1.0, loss_fn: mean_absolute_error, accuracy: [0.00022440413886215538], loss: [2937588.5], 

101/101 [==============================] - 120s 835ms/step - loss: 38.6210 - accuracy: 0.9839
Epoch 1/2
101/101 [==============================] - 119s 854ms/step - loss: 37.8250 - accuracy: 0.9938
Epoch 2/2
101/101 [==============================] - 118s 841ms/step - loss: 37.1701 - accuracy: 0.9938
Epoch 1/3
101/101 [==============================] - 119s 850ms/step - loss: 36.6225 - accuracy: 0.9938
Epoch 2/3
101/101 [==============================] - 119s 848ms/step - loss: 36.1597 - accuracy: 0.9938
Epoch 3/3
101/101 [==============================] - 119s 854ms/step - loss: 35.7648 - accuracy: 0.9938
optimizer: Ftrl, learning_rate: 1.0, loss_fn: mean_squared_error, accuracy: [0.9937754273414612, 0.9937818646430969, 0.9937871694564819], loss: [36.622520446777344, 36.15966033935547, 35.76478576660156], 

101/101 [==============================] - 123s 874ms/step - loss: 0.0783 - accuracy: 0.9938
Epoch 1/2
101/101 [==============================] - 117s 833ms/step - loss: 0.0777 - accuracy: 0.9938
Epoch 2/2
101/101 [==============================] - 115s 814ms/step - loss: 0.0771 - accuracy: 0.9938
Epoch 1/3
101/101 [==============================] - 121s 871ms/step - loss: 0.0766 - accuracy: 0.9938
Epoch 2/3
101/101 [==============================] - 121s 874ms/step - loss: 0.0760 - accuracy: 0.9938
Epoch 3/3
101/101 [==============================] - 121s 874ms/step - loss: 0.0756 - accuracy: 0.9938
Epoch 1/4
101/101 [==============================] - 118s 849ms/step - loss: 0.0751 - accuracy: 0.9938
Epoch 2/4
101/101 [==============================] - 117s 841ms/step - loss: 0.0746 - accuracy: 0.9938
Epoch 3/4
101/101 [==============================] - 117s 840ms/step - loss: 0.0742 - accuracy: 0.9938
Epoch 4/4
101/101 [==============================] - 118s 842ms/step - loss: 0.0738 - accuracy: 0.9938
Epoch 1/5
101/101 [==============================] - 117s 835ms/step - loss: 0.0734 - accuracy: 0.9938
Epoch 2/5
101/101 [==============================] - 117s 831ms/step - loss: 0.0730 - accuracy: 0.9938
Epoch 3/5
101/101 [==============================] - 116s 829ms/step - loss: 0.0726 - accuracy: 0.9938
Epoch 4/5
101/101 [==============================] - 118s 846ms/step - loss: 0.0722 - accuracy: 0.9938
Epoch 5/5
101/101 [==============================] - 116s 826ms/step - loss: 0.0719 - accuracy: 0.9938
optimizer: Ftrl, learning_rate: 1.0, loss_fn: mean_squared_logarithmic_error, accuracy: [0.9937806129455566, 0.9937731027603149, 0.9937837719917297, 0.9937859773635864, 0.9937738180160522], loss: [0.07335256040096283, 0.07296431064605713, 0.07259127497673035, 0.07223349809646606, 0.07189014554023743], 

101/101 [==============================] - 120s 840ms/step - loss: 0.3710 - accuracy: 0.9938
Epoch 1/2
101/101 [==============================] - 122s 878ms/step - loss: 0.3669 - accuracy: 0.9938
Epoch 2/2
101/101 [==============================] - 122s 878ms/step - loss: 0.3641 - accuracy: 0.9938
Epoch 1/3
101/101 [==============================] - 116s 817ms/step - loss: 0.3620 - accuracy: 0.9938
Epoch 2/3
101/101 [==============================] - 115s 810ms/step - loss: 0.3602 - accuracy: 0.9938
Epoch 3/3
101/101 [==============================] - 117s 827ms/step - loss: 0.3586 - accuracy: 0.9938
Epoch 1/4
101/101 [==============================] - 118s 845ms/step - loss: 0.3573 - accuracy: 0.9938
Epoch 2/4
101/101 [==============================] - 117s 841ms/step - loss: 0.3561 - accuracy: 0.9938
Epoch 3/4
101/101 [==============================] - 119s 848ms/step - loss: 0.3550 - accuracy: 0.9938
Epoch 4/4
101/101 [==============================] - 118s 841ms/step - loss: 0.3540 - accuracy: 0.9938
Epoch 1/5
101/101 [==============================] - 119s 848ms/step - loss: 0.3532 - accuracy: 0.9938
Epoch 2/5
101/101 [==============================] - 119s 842ms/step - loss: 0.3524 - accuracy: 0.9938
Epoch 3/5
101/101 [==============================] - 118s 841ms/step - loss: 0.3516 - accuracy: 0.9938
Epoch 4/5
 12/101 [==>...........................] - ETA: 1:13 - loss: 0.3485 - accuracy: 0.9938